
# Appendice tecnica â€” Indexing, Context Management e Parametri LLM

## A. Algoritmi di indexing vettoriale

### A.1 PerchÃ© lâ€™indexing Ã¨ critico

In un sistema con ~10.000 CV, lâ€™indexing:

* non Ã¨ un dettaglio implementativo
* **influenza direttamente precisione, latenza e stabilitÃ **
* deve essere **prevedibile e riproducibile**

Il vector store non Ã¨ un database tradizionale:
usa **Approximate Nearest Neighbors (ANN)**.

---

### A.2 Algoritmo consigliato: HNSW

Per Qdrant (e sistemi analoghi), lâ€™algoritmo di riferimento Ã¨:

**HNSW â€“ Hierarchical Navigable Small World**

Caratteristiche:

* ricerca sub-lineare
* ottimo trade-off precisione / performance
* stabile su dataset medi (10kâ€“1M vettori)

PerchÃ© Ã¨ adatto al tuo caso:

* workload read-heavy
* K ridotti (20â€“50)
* dataset che cresce nel tempo
* supporta filtri metadata senza degrado grave

---

### A.3 Implicazioni architetturali (da sapere)

* Lâ€™index Ã¨ **approssimato**, non esatto
* Due query identiche possono restituire:

  * stesso set
  * ordine leggermente diverso

ðŸ‘‰ **Non basare decisioni finali sullâ€™ordine del ranking vettoriale**
ðŸ‘‰ Usare la vector search **solo per shortlist**

---

### A.4 Antipattern di indexing

* usare vector score come punteggio finale
* confrontare score tra collection diverse
* ri-indicizzare spesso per dati volatili

---

## B. Context normalization e augmentation

### B.1 Cosâ€™Ã¨ il â€œcontextâ€ nel tuo sistema

Il contesto Ã¨ **lâ€™input cognitivo dellâ€™LLM**, non:

* il risultato del retrieval
* nÃ© lâ€™intero CV

Ma:

> **una rappresentazione controllata, normalizzata e intenzionale**

---

### B.2 Context normalization (obbligatoria)

Obiettivi:

* ridurre rumore
* eliminare ambiguitÃ 
* rendere confrontabili i CV

Tecniche concettuali:

* ordine fisso delle sezioni
* stesso schema per ogni CV
* lessico normalizzato (skill dal dizionario)

Esempio logico:

1. Skill normalizzate (sempre prima)
2. Esperienze rilevanti (dopo)
3. Altre informazioni (opzionali)

ðŸ‘‰ La normalizzazione **vale piÃ¹ dellâ€™embedding**.

---

### B.3 Context augmentation (controllata)

Lâ€™augmentation NON Ã¨:

* aggiungere informazioni inventate
* inferire skill non presenti

Ãˆ:

* **arricchire con informazioni strutturali**
* rendere esplicito ciÃ² che Ã¨ giÃ  implicito

Esempi leciti:

* associare una esperienza a una skill giÃ  dichiarata
* esplicitare seniority se presente nel testo
* raggruppare esperienze simili

Esempi illeciti:

* dedurre skill non dichiarate
* inferire capacitÃ  â€œprobabiliâ€
* usare conoscenza esterna non tracciata

---

### B.4 Regola dâ€™oro

> **Il contesto puÃ² essere riorganizzato e chiarito,
> ma mai â€œmigliorato semanticamenteâ€.**

---

## C. Parametri LLM: temperatura, token, source

#### C.1 Temperatura

Nel tuo sistema lâ€™LLM:

* non crea contenuti creativi
* prende decisioni spiegate

ðŸ‘‰ **Temperatura consigliata: bassa (0.0 â€“ 0.3)**

Motivo:

* output stabile
* spiegazioni ripetibili
* auditabilitÃ 

Temperatura alta = variabilitÃ  = rischio HR.

---

### C.2 Token management

Principi:

* il contesto deve stare **comodamente** sotto il limite
* il modello deve avere spazio per ragionare

Strategia:

* limitare il numero di CV completi (5â€“7 max)
* chunk brevi e densi
* preferire liste a testo narrativo

ðŸ‘‰ Se tagli token a caso, **tagli il ragionamento**.

---

### C.3 Source attribution (fondamentale)

Ogni affermazione dellâ€™LLM deve poter essere ricondotta a:

* CV_ID
* sezione (skill / experience)
* chunk o elemento

Non serve citazione verbosa, ma:

* riferimento strutturale
* tracciabile nei log

Esempio concettuale:

> â€œLa scelta Ã¨ basata sulle skill X e Y presenti nel CV_ID=123, sezione Skill.â€

---

### C.4 Antipattern LLM

* temperature alte â€œper sembrare piÃ¹ intelligentiâ€
* prompt lunghi e non strutturati
* contesto non omogeneo tra CV
* mancanza di riferimenti alle fonti

---

## Principio finale di chiusura

> **La qualitÃ  del sistema non dipende dal modello,
> ma da come indicizzi, normalizzi e controlli il contesto.**
